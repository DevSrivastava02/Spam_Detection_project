{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54cf054b",
   "metadata": {},
   "source": [
    "SMS SPAM DECTION  SOLVE USING THE BOW "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49306c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     label                                            message\n",
      "0      ham  Go until jurong point, crazy.. Available only ...\n",
      "1      ham                      Ok lar... Joking wif u oni...\n",
      "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3      ham  U dun say so early hor... U c already then say...\n",
      "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
      "...    ...                                                ...\n",
      "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568   ham               Will Ã¼ b going to esplanade fr home?\n",
      "5569   ham  Pity, * was in mood for that. So...any other s...\n",
      "5570   ham  The guy did some bitching but I acted like i'd...\n",
      "5571   ham                         Rofl. Its true to its name\n",
      "\n",
      "[5572 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "massage=pd.read_csv(\"SMScollection.csv\",sep=\"\\t\",names=['label','message'])\n",
    "print(massage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf1f702",
   "metadata": {},
   "source": [
    "DATA CLEANING AND PREPROCESSING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d480478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "# import nltk\n",
    "# from nltk.stem import sent_tokenization\n",
    "# sentence=sent_tokenization(massage)\n",
    "# print(sentence)\n",
    "\n",
    "# from nltk.stem import word_tokenization\n",
    "# word=word_tokenization(sentence)\n",
    "# print(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7947b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Create an object of PorterStemmer\n",
    "Porter_Stemmer = PorterStemmer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadfcac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76f4728",
   "metadata": {},
   "source": [
    "THE LINE CODE DOWN SIDE UESD IN ALL THE DATA CLEANING STEP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fe8a6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['go jurong point crazi avail bugi n great world la e buffet cine got amor wat', 'ok lar joke wif u oni', 'free entri wkli comp win fa cup final tkt st may text fa receiv entri question std txt rate c appli', 'u dun say earli hor u c alreadi say', 'nah think goe usf live around though', 'freemsg hey darl week word back like fun still tb ok xxx std chg send rcv', 'even brother like speak treat like aid patent', 'per request mell mell oru minnaminungint nurungu vettam set callertun caller press copi friend callertun', 'winner valu network custom select receivea prize reward claim call claim code kl valid hour', 'mobil month u r entitl updat latest colour mobil camera free call mobil updat co free']\n"
     ]
    }
   ],
   "source": [
    "corpus = []\n",
    "for i in range(0, len(massage)):   # assuming your DataFrame is messages, not massage\n",
    "    # Keep only letters\n",
    "    review = re.sub('[^a-zA-Z]', ' ', massage['message'][i])\n",
    "    review = review.lower()  # convert to lowercase\n",
    "    review = review.split()  # tokenize into words\n",
    "    \n",
    "    # Remove stopwords and apply stemming\n",
    "    review = [Porter_Stemmer.stem(word) for word in review if word not in set(stopwords.words('english'))]\n",
    "    \n",
    "    # Join back into one string\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    corpus.append(review)\n",
    "\n",
    "print(corpus[:10])   # show first 10 cleaned messages\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d06a25",
   "metadata": {},
   "source": [
    "CREATE THE BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4670941c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], shape=(5572, 100))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "Count_Vectorizer=CountVectorizer(max_features=100,binary=True)\n",
    "x=Count_Vectorizer.fit_transform(corpus).toarray()\n",
    "print(x)\n",
    "x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
